{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1727407895008,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "Q47_PUzzDjtT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import random\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1909,
     "status": "ok",
     "timestamp": 1727407898556,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "-TtBawIAFh5e"
   },
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "        L2 = 1e-2\n",
    "        self.weights_L2 = L2\n",
    "        self.biases_L2  = L2\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "        self.dbiases  = self.dbiases  + 2* self.biases_L2 *self.biases\n",
    "        self.dweights = self.dweights + 2* self.weights_L2 *self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1727407941740,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "w8BDyhKCDsEh"
   },
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, kShape, kNumber):\n",
    "        self.xKShape = kShape[0]\n",
    "        self.yKShape = kShape[1]\n",
    "        self.kNumber = kNumber\n",
    "\n",
    "        self.weights = np.random.rand(self.xKShape, self.yKShape, kNumber)\n",
    "        self.biases = np.random.rand(1, kNumber)\n",
    "\n",
    "        L2 = 1e-2\n",
    "        self.weights_L2 = L2\n",
    "        self.biases_L2  = L2\n",
    "\n",
    "    def forward(self, imageMatrix, padding = 0, stride = 1):\n",
    "        [xImageShape, yImageShape, channelSize, batchSize] = imageMatrix.shape\n",
    "\n",
    "        xOutput = int((xImageShape - self.xKShape + 2 * padding ) / stride + 1)\n",
    "        yOutput = int((yImageShape - self.yKShape + 2 * padding ) / stride + 1)\n",
    "\n",
    "        output = np.zeros((xOutput, yOutput, channelSize, self.kNumber, batchSize))\n",
    "\n",
    "        imagePadded = np.zeros((xImageShape + 2 * padding, yImageShape + 2*padding, channelSize, self.kNumber, batchSize))\n",
    "\n",
    "        for k in range(self.kNumber):\n",
    "            imagePadded[int(padding): int(padding + xImageShape), int(padding): int(padding + yImageShape), :,k,:] = imageMatrix\n",
    "\n",
    "\n",
    "        if channelSize == 6 & self.kNumber == 16:\n",
    "            filt = np.array([[1,0,0,0,1,1,1,0,0,1,1,1,1,0,1,1],\n",
    "                             [1,1,0,0,0,1,1,1,0,0,1,1,1,1,0,1],\n",
    "                             [1,1,1,0,0,0,1,1,1,0,0,1,0,1,1,1],\n",
    "                             [0,1,1,1,0,0,1,1,1,1,0,0,1,0,1,1],\n",
    "                             [0,0,1,1,1,0,0,1,1,1,1,0,1,1,0,1],\n",
    "                             [0,0,0,1,1,1,0,0,1,1,1,1,0,1,1,1]])\n",
    "\n",
    "        else:\n",
    "            filt = np.ones([channelSize,self.kNumber])\n",
    "\n",
    "        self.filt = filt\n",
    "\n",
    "        for i in range(batchSize):\n",
    "            for k in range(self.kNumber):\n",
    "                for c in range(channelSize):\n",
    "                    if filt[c, k] == 1:\n",
    "                        for x in range(xOutput):\n",
    "                            for y in range(yOutput):\n",
    "                                yStart = y * stride\n",
    "                                yEnd = yStart + self.yKShape\n",
    "                                xStart = x * stride\n",
    "                                xEnd = xStart + self.xKShape\n",
    "\n",
    "                                currentSlice = imagePadded[xStart:xEnd, yStart:yEnd, c, k, i]\n",
    "                                imgSlice_k_mul = np.multiply(currentSlice, self.weights[:, :, k])\n",
    "                                output[x, y, c, k, i] = np.sum(imgSlice_k_mul) + self.biases[0, k].astype(float)\n",
    "\n",
    "        self.output =  output.sum(2)\n",
    "        self.input = imageMatrix\n",
    "        self.paddedInput = imagePadded\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        stride = self.stride\n",
    "        padding = self.padding\n",
    "        xk = self.xKShape\n",
    "        yk = self.yKShape\n",
    "        nk = self.kNumber\n",
    "        weights = self.weights\n",
    "        paddedImage = self.paddedInput\n",
    "\n",
    "        paddedImageShape = paddedImage.shape\n",
    "        dinputs = np.zeros((paddedImageShape[0], paddedImageShape[1], paddedImageShape[2], paddedImageShape[4]))\n",
    "\n",
    "        dbiases = np.zeros(self.biases.shape)\n",
    "        dweights = np.zeros(self.weights.shape)\n",
    "\n",
    "        xd = dvalues.shape[0]\n",
    "        yd = dvalues.shape[1]\n",
    "        numChan = paddedImageShape[2]\n",
    "        batchSize = paddedImageShape[4]\n",
    "\n",
    "        imagePadded = paddedImage[:,:,:,0,:]\n",
    "        filt = self.filt\n",
    "\n",
    "        for i in range(batchSize):\n",
    "            for c in range(numChan):\n",
    "                for k in range(nk):\n",
    "                    if filt[c, k] == 1:\n",
    "                      for y in range(yd):\n",
    "                          for x in range(xd):\n",
    "                              yStart = y * stride\n",
    "                              yEnd = yStart + yk\n",
    "                              xStart = x * stride\n",
    "                              xEnd = xStart + xk\n",
    "\n",
    "                              sx = slice(xStart, xEnd)\n",
    "                              sy = slice(yStart, yEnd)\n",
    "\n",
    "                              currentSlice = imagePadded[sx, sy, c, i]\n",
    "                              dweights[:,:,k] += currentSlice * dvalues[x,y,k,i]\n",
    "                              dinputs[sx, sy, c, i] += dweights[:,:,k] * dvalues[x,y,k,i]\n",
    "\n",
    "                    dbiases[0,k] = np.sum(np.sum(weights[:,:,k], axis = 0), axis = 0)\n",
    "\n",
    "        dinputs = dinputs[padding: paddedImageShape[0]-padding, padding: paddedImageShape[1]-padding, :, :]\n",
    "        self.dinputs = dinputs\n",
    "\n",
    "        self.dbiases  = dbiases  + 2 * self.biases_L2 * self.biases\n",
    "        self.dweights = dweights + 2 * self.weights_L2 * self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1727407898557,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "DED8XbAEDwUH"
   },
   "outputs": [],
   "source": [
    "class FlattenLayer:\n",
    "    def forward(self, imageMatrix):\n",
    "        [xImageSize, yImageSize, channelSize, batchSize] = imageMatrix.shape\n",
    "        flatLayerSize = xImageSize * yImageSize * channelSize\n",
    "\n",
    "        flat_data = np.zeros((batchSize, flatLayerSize))\n",
    "\n",
    "        for i in range(batchSize):\n",
    "            flat_data[i, :] = imageMatrix[:,:,:,i].reshape(1, flatLayerSize)\n",
    "\n",
    "        self.output = flat_data\n",
    "        self.input = imageMatrix\n",
    "\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        [xImage, yImage, channelSize, batchSize] = self.input.shape\n",
    "\n",
    "        dinputs = np.zeros(self.input.shape)\n",
    "\n",
    "        for i in range(batchSize):\n",
    "            dinputs[:,:,:,i] = dvalues[i,:].reshape(xImage, yImage, channelSize)\n",
    "\n",
    "        self.dinputs = dinputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1727407898557,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "fzXoO40tD3Ol"
   },
   "outputs": [],
   "source": [
    "class Average_Pool:\n",
    "\n",
    "    def forward(self, M, stride = 1, KernShape = 2):\n",
    "\n",
    "        xImgShape  = M.shape[0]\n",
    "        yImgShape  = M.shape[1]\n",
    "        numChans   = M.shape[2]\n",
    "        numImds    = M.shape[3]\n",
    "\n",
    "        self.inputs = M\n",
    "\n",
    "        xK = KernShape\n",
    "        yK = KernShape\n",
    "\n",
    "        xOutput = int(((xImgShape - xK) / stride) + 1)\n",
    "        yOutput = int(((yImgShape - yK) / stride) + 1)\n",
    "\n",
    "        imagePadded = M\n",
    "\n",
    "        output = np.zeros((xOutput,yOutput,numChans,numImds))\n",
    "\n",
    "        for i in range(numImds):# loop over number of images\n",
    "            currentIm_pad = imagePadded[:,:,:,i] #select ith padded image\n",
    "            for y in range(yOutput):# loop over vert axis of output\n",
    "                for x in range(xOutput):# loop over hor axis of output\n",
    "                    for c in range(numChans):# loop over channels (= #filters)\n",
    "\n",
    "                    # finding corners of the current \"slice\"\n",
    "                        y_start = y*stride\n",
    "                        y_end   = y*stride + yK\n",
    "                        x_start = x*stride\n",
    "                        x_end   = x*stride + xK\n",
    "\n",
    "                        sx      = slice(x_start,x_end)\n",
    "                        sy      = slice(y_start,y_end)\n",
    "\n",
    "                        current_slice = currentIm_pad[sx,sy,c]\n",
    "\n",
    "                        #actual average pool\n",
    "                        slice_mean         = float(current_slice.mean())\n",
    "                        output[x, y, c, i] = slice_mean\n",
    "\n",
    "\n",
    "        #storing info, also for backpropagation\n",
    "        self.xKernShape = xK\n",
    "        self.yKernShape = yK\n",
    "        self.output     = output\n",
    "        self.impad      = imagePadded\n",
    "        self.stride     = stride\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        xd = dvalues.shape[0]\n",
    "        yd = dvalues.shape[1]\n",
    "\n",
    "        numChans = dvalues.shape[2]\n",
    "        numImds  = dvalues.shape[3]\n",
    "\n",
    "        imagePadded = self.impad\n",
    "        dinputs     = np.zeros(imagePadded.shape)\n",
    "        Ones        = np.ones(imagePadded.shape)#for backprop\n",
    "\n",
    "        stride  = self.stride\n",
    "        xK      = self.xKernShape\n",
    "        yK      = self.yKernShape\n",
    "\n",
    "        Ones    = Ones/xK/yK # normalization that came from average pool\n",
    "\n",
    "        for i in range(numImds):# loop over number of images\n",
    "            for y in range(yd):# loop over vert axis of output\n",
    "                for x in range(xd):# loop over hor axis of output\n",
    "                    for c in range(numChans):# loop over channels (= #filters)\n",
    "\n",
    "                        # finding corners of the current \"slice\"\n",
    "                        y_start = y*stride\n",
    "                        y_end   = y*stride + yK\n",
    "                        x_start = x*stride\n",
    "                        x_end   = x*stride + xK\n",
    "\n",
    "                        sx      = slice(x_start,x_end)\n",
    "                        sy      = slice(y_start,y_end)\n",
    "\n",
    "                        dinputs[sx,sy,c,i]  += Ones[sx,sy,c,i]*dvalues[x,y,c,i]\n",
    "\n",
    "\n",
    "        self.dinputs = dinputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1727407898558,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "9FaJ3SaZDzOL"
   },
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def forward(self, input):\n",
    "        tanh = np.tanh(input)\n",
    "        self.output = tanh\n",
    "        self.input= input\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        deriv = 1 - self.output**2\n",
    "        deriv = np.nan_to_num(deriv)\n",
    "        self.dinputs = np.multiply(deriv, dvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1727407898559,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "PBUp5F6gD_LK"
   },
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in \\\n",
    "                enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                              np.dot(single_output, single_output.T)\n",
    "\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "                                         single_dvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1727407898559,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "whep7ZBnD_va"
   },
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return (data_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1727407898560,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "DeWnieP0EEM3"
   },
   "outputs": [],
   "source": [
    "class SoftmaxLossGrad():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss       = CategoricalCrossEntropy()\n",
    "\n",
    "    def forward(self, inputs, y_true):\n",
    "        self.activation.forward(inputs)\n",
    "        self.output = self.activation.output\n",
    "        #the probabilities\n",
    "        #calculates and returns mean loss\n",
    "        return(self.loss.calculate(self.output, y_true))\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        Nsamples = len(dvalues)\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis = 1)\n",
    "        self.dinputs = dvalues.copy()\n",
    "        #calculating normalized gradient\n",
    "        self.dinputs[range(Nsamples), y_true] -= 1\n",
    "        self.dinputs = self.dinputs/Nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1727407898560,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "GUHz6LxeFrn0"
   },
   "outputs": [],
   "source": [
    "class CategoricalCrossEntropy(Loss):\n",
    "     def forward(self, y_pred, y_true):\n",
    "         samples = len(y_pred)\n",
    "         #removing vals close to zero and one bco log and accuracy\n",
    "         y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "         #now, depending on how classes are coded, we need to get the probs\n",
    "         if len(y_true.shape) == 1:#classes are encoded as [[1],[2],[2],[4]]\n",
    "             correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "         elif len(y_true.shape) == 2:#classes are encoded as\n",
    "                                    #[[1,0,0], [0,1,0], [0,1,0]]\n",
    "             correct_confidences = np.sum(y_pred_clipped*y_true, axis = 1)\n",
    "         #now: calculating actual losses\n",
    "         negative_log_likelihoods = -np.log(correct_confidences)\n",
    "         return negative_log_likelihoods\n",
    "\n",
    "     def backward(self, dvalues, y_true):\n",
    "         Nsamples = len(dvalues)\n",
    "         Nlabels  = len(dvalues[0])\n",
    "         #turning labels into one-hot i. e. [[1,0,0], [0,1,0], [0,1,0]], if\n",
    "         #they are not\n",
    "         if len(y_true.shape) == 1:\n",
    "            #\"eye\" turns it into a diag matrix, then indexing via the label\n",
    "            #itself\n",
    "            y_true = np.eye(Nlabels)[y_true]\n",
    "         #normalized gradient\n",
    "         self.dinputs = -y_true/dvalues/Nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1727407898560,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "YeNFAcdHEKq8"
   },
   "outputs": [],
   "source": [
    "class Optimizer_SGD:\n",
    "    #initializing with a default learning rate of 0.1\n",
    "    def __init__(self, learning_rate = 1, decay = 0, momentum = 0):\n",
    "        self.learning_rate        = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay                 = decay\n",
    "        self.iterations            = 0\n",
    "        self.momentum              = momentum\n",
    "\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1/ (1 + self.decay*self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        #if we use momentum\n",
    "        if self.momentum:\n",
    "\n",
    "            #check if layer has attribute \"momentum\"\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums   = np.zeros_like(layer.biases)\n",
    "\n",
    "            #now the momentum parts\n",
    "            weight_updates = self.momentum * layer.weight_momentums - \\\n",
    "                self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            bias_updates = self.momentum * layer.bias_momentums - \\\n",
    "                self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "\n",
    "        else:\n",
    "\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates   = -self.current_learning_rate * layer.dbiases\n",
    "\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases  += bias_updates\n",
    "\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1727407898560,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "GzfAmw3kCAsd"
   },
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    def __init__(self, dataset):\n",
    "        self.extract_train_data(dataset)\n",
    "\n",
    "        self.n_neuron = 84\n",
    "        self.n_input = 480\n",
    "        self.conv1 = ConvLayer([5,5], 6)\n",
    "        self.conv2 = ConvLayer([5,5], 16)\n",
    "        self.conv3 = ConvLayer([5,5], 120)\n",
    "        self.ap1 = Average_Pool()\n",
    "        self.ap2 = Average_Pool()\n",
    "        self.activation_tanh = [Tanh() for i in range(4)]\n",
    "        self.flat_layer = FlattenLayer()\n",
    "        self.dense1 = Layer_Dense(self.n_input, self.n_neuron)\n",
    "        self.dense_final = Layer_Dense(self.n_neuron, self.n_category)\n",
    "        self.loss_activation = SoftmaxLossGrad()\n",
    "        self.optimizer = Optimizer_SGD()\n",
    "\n",
    "\n",
    "    def extract_train_data(self, dataset):\n",
    "        (trainX, trainY), (testX, testY) = dataset\n",
    "        self.trainX = trainX\n",
    "        self.trainY = trainY\n",
    "        self.testX = testX\n",
    "        self.testY = testY\n",
    "        self.n_category = len(np.unique(self.trainY))\n",
    "        self.n_total = range(len(trainY))\n",
    "\n",
    "\n",
    "\n",
    "    def run_training(self,\n",
    "                     minibatch_size=64,\n",
    "                     iteration=1,\n",
    "                     epochs=1,\n",
    "                     learning_rate=0.1,\n",
    "                     decay=0.001,\n",
    "                     momentum=0.5,\n",
    "                     saved_weights=\"NO\"):\n",
    "        n_total = self.n_total\n",
    "\n",
    "        for e in range(epochs):\n",
    "            idx = random.sample(n_total, minibatch_size)\n",
    "            M = self.trainX[:,:,:, idx]\n",
    "            C = self.trainY[idx]\n",
    "            ie      = iteration * epochs\n",
    "            Monitor = np.zeros((ie,3))\n",
    "            ct      = 0\n",
    "\n",
    "            for it in range(iteration):\n",
    "                self.conv1.forward(M,0,1)\n",
    "                self.activation_tanh[0].forward(self.conv1.output)\n",
    "                self.ap1.forward(self.activation_tanh[0].output, 2, 2)\n",
    "\n",
    "                self.conv2.forward(self.ap1.output, 0,1)\n",
    "                self.activation_tanh[1].forward(self.conv2.output)\n",
    "                self.ap2.forward(self.activation_tanh[1].output, 2, 2)\n",
    "\n",
    "                self.conv3.forward(self.ap2.output, 2, 3)\n",
    "                self.activation_tanh[2].forward(self.conv3.output)\n",
    "\n",
    "                self.flat_layer.forward(self.activation_tanh[2].output)\n",
    "                self.dense1.forward(self.flat_layer.output)\n",
    "                self.activation_tanh[3].forward(self.dense1.output)\n",
    "                self.dense_final.forward(self.activation_tanh[3].output)\n",
    "\n",
    "                loss = self.loss_activation.forward(self.dense_final.output, C)\n",
    "\n",
    "                self.predictions = np.argmax(self.loss_activation.output, axis=1)\n",
    "                if len(C.shape) == 2:\n",
    "                    C = np.argmax(C, axis=1)\n",
    "                self.accuracy = np.mean(self.predictions == C)\n",
    "\n",
    "\n",
    "                ##backward\n",
    "                self.loss_activation.backward(self.loss_activation.output, C)\n",
    "                self.dense_final.backward(self.loss_activation.dinputs)\n",
    "                self.activation_tanh[3].backward(self.dense_final.dinputs)\n",
    "                self.dense1.backward(self.activation_tanh[3].dinputs)\n",
    "                self.flat_layer.backward(self.dense1.dinputs)\n",
    "                self.activation_tanh[2].backward(self.flat_layer.dinputs)\n",
    "                self.conv3.backward(self.activation_tanh[2].dinputs)\n",
    "                self.ap2.backward(self.conv3.dinputs)\n",
    "                self.activation_tanh[1].backward(self.ap2.dinputs)\n",
    "                self.conv2.backward(self.activation_tanh[1].dinputs)\n",
    "                self.ap1.backward(self.conv2.dinputs)\n",
    "                self.activation_tanh[0].backward(self.ap1.dinputs)\n",
    "                self.conv1.backward(self.activation_tanh[0].dinputs)\n",
    "\n",
    "                self.optimizer.pre_update_params()\n",
    "\n",
    "                self.optimizer.update_params(self.dense1)\n",
    "                self.optimizer.update_params(self.dense_final)\n",
    "\n",
    "                self.optimizer.update_params(self.conv1)\n",
    "                self.optimizer.update_params(self.conv2)\n",
    "                self.optimizer.update_params(self.conv3)\n",
    "\n",
    "                self.optimizer.post_update_params()\n",
    "\n",
    "                Monitor[ct,0] = self.accuracy\n",
    "                Monitor[ct,1] = loss\n",
    "                Monitor[ct,2] = self.optimizer.current_learning_rate\n",
    "\n",
    "                ct += 1\n",
    "\n",
    "                print(f'epoch: {e}, ' +\n",
    "                      f'iteration : {it} ' +\n",
    "                      f'accuracy: {self.accuracy: .3f}, ' +\n",
    "                      f'loss: {loss: .3f}, ' +\n",
    "                      f'current learning rate: {self.optimizer.current_learning_rate: .5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1727407898561,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "C9eLs9jjEjWi"
   },
   "outputs": [],
   "source": [
    "class DatasetLoader:\n",
    "    def load_mnist_data(self):\n",
    "        (trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "        #convert shape (sampleSize x Height x Width) to (Height x Width x sampleSize)\n",
    "        trainX = trainX.transpose(1,2,0)\n",
    "        testX = testX.transpose(1,2,0)\n",
    "\n",
    "        #convert single channel image into 3 channel image for both test and train data\n",
    "        shape_train = trainX.shape\n",
    "        shape_test = testX.shape\n",
    "\n",
    "        trainX_3d = np.zeros((shape_train[0], shape_train[1], 3, shape_train[2]))\n",
    "        textX_3d = np.zeros((shape_test[0], shape_test[1], 3, shape_test[2]))\n",
    "\n",
    "        for imageChannelIndex in range(2):\n",
    "            trainX_3d[:,:,imageChannelIndex,:] = trainX\n",
    "            textX_3d[:,:,imageChannelIndex,:] = testX\n",
    "\n",
    "        self.mnist_data = (trainX_3d, trainY), (textX_3d, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44728,
     "status": "ok",
     "timestamp": 1727407991470,
     "user": {
      "displayName": "Yeahia Md Arif",
      "userId": "17234423732122891639"
     },
     "user_tz": -360
    },
    "id": "jhAC-RLhEen7",
    "outputId": "dd3899e8-d860-4181-adc9-3f6c2f93b30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration : 0 accuracy:  0.078, loss:  2.302, current learning rate:  1.00000\n"
     ]
    }
   ],
   "source": [
    "dl = DatasetLoader()\n",
    "dl.load_mnist_data()\n",
    "(trainX, trainY), (testX, testY) = dl.mnist_data\n",
    "\n",
    "lenet = LeNet(dl.mnist_data)\n",
    "lenet.run_training()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNMK1KIGv3JbJg0Fkpcvy8D",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
